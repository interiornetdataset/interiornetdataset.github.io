<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-9795741-6"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-9795741-6');
</script>


	<title>InteriorNet: Mega-scale Multi-sensor Photo-realistic Indoor Scenes Dataset</title>
	<meta name="author" content="Wenbin Li">
	<link rel="stylesheet" type="text/css" href="./items/styles.css">
	<link rel="stylesheet" type="text/css" href="./items/thickbox.css" media="screen">
    <script type="text/javascript" src="./items/jquery.js" charset="utf-8"></script><style type="text/css"></style>
    <script type="text/javascript" src="./items/thickbox.js" charset="utf-8"></script>
</head>
<body screen_capture_injected="true">
	<div id="centerwrap">
	<div id="innerwrap">
		<div id="head">
			<h1>InteriorNet: Mega-scale Multi-sensor Photo-realistic <br> Indoor Scenes Dataset</h1>
			<h3>Wenbin Li, Sajad Saeedi, John McCormac, Ronald Clark, Dimos Tzoumanikas, <br> 
           Qing Ye, Yuzhong Huang, Rui Tang and Stefan Leutenegger</h3>
            <h4>Imperial College London&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Kujiale.com
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;University of Southern California</h4>
            <br>
		</div>
		<div class="hr"><!-- --></div>
		<br>
		<br>

		<div id="content">
			    <iframe width="782" height="440" src="https://www.youtube.com/embed/z8uJh_xUq7A?rel=0&amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
				<br><br><br><br>

<center style="">

				<table bgcolor="#808080" border="0" width="100%"><tbody><tr>
				<td><font color="#EBEBEB" size="3" face="verdana"><strong>Dataset Overview</strong></font></td>
				</tr></tbody></table> <br>

				<table>
				<tbody><tr><td><img src="./items/InteriorNet.jpg" width="750"></td></tr>
				</tbody></table><br>
				<div align="justify">System Overview: an end-to-end pipeline to render an RGB-D-inertial benchmark for large scale interior scene understanding and mapping. Our dataset contains <strong>20M</strong> images created by pipeline: (<strong>A</strong>) We collect around 1 million CAD models provided by world-leading furniture manufacturers. These models have been used in the real-world production. (<strong>B</strong>) Based on those models, around 1,100 professional designers create around 22 million interior layouts. Most of such layouts have been used in real-world decorations. (<strong>C</strong>) For each layout, we generate a number of configurations to represent different random lightings and simulation of scene change over time in daily life. (<strong>D</strong>) We provide an interactive simulator (<em>ViSim</em>) to help for creating ground truth IMU, events, as well as monocular or stereo camera trajectories including hand-drawn, random walking and neural network based realistic trajectory. (<strong>E</strong>) All supported image sequences and ground truth. </div><br><br>
				
<!-- 				<table bgcolor="#808080" border="0" width="100%"><tbody><tr>
				<td><font color="#EBEBEB" size="3" face="verdana"><strong>ViSim : An Interactive Simulator</strong></font></td>
				</tr></tbody></table> <br>
				
				<table>
				<tbody><tr><td><img src="./items/InteriorNet_sim.jpg" width="750"></td></tr>
				</tbody></table>
				<div align="justify"><em>ViSim</em>: Our interactive simulator. <em>ViSim</em> contains a design view, an information panel as well as a set of options for camera settings, trajectory smoothness, trajectory adjustment and IMU and Events settings. </div><br><br><br> -->
				
<!-- 				<table>
				<tbody><tr><td><img src="./items/InteriorNet_labels.jpg" width="750"></td></tr>
				</tbody></table><br>
				<div align="justify">Our rendered images and the associated NYU40 labels. </div><br> -->
				

				<table bgcolor="#808080" border="0" width="100%"><tbody><tr>
				<td><font color="#EBEBEB" size="3" face="verdana"><strong>Download and License</strong></font></td>
				</tr></tbody></table> <br>
				<p align="justify">
				Coming Soon.
				</p><br>
				<table bgcolor="#808080" border="0" width="100%"><tbody><tr>
				<td><font color="#EBEBEB" size="3" face="verdana"><strong>Citation</strong></font></td>
				</tr></tbody></table>
					<pre><p align="left">
@inproceedings { InteriorNet18,
      author = { Wenbin Li and Sajad Saeedi and John McCormac and Ronald Clark and 
                 Dimos Tzoumanikas and Qing Ye and Yuzhong Huang and Rui Tang and 
                 Stefan Leutenegger },
   booktitle = { British Machine Vision Conference (BMVC) },
       title = { InteriorNet: Mega-scale Multi-sensor Photo-realistic Indoor Scenes Dataset },
        year = { 2018 }
}
					</p></pre>

		<table bgcolor="#808080" border="0" width="100%"><tbody><tr>
<td><font color="#EBEBEB" size="3" face="verdana"><strong>Acknowledgements</strong></font></td>
</tr></tbody></table> <br>
		<p align="justify">
			We would like to thank <a href="Kujiale.com"><strong>Kujiale.com</strong></a> for providing their database of production furniture models and layouts, as well as access to their GPU/CPU clusters. We also thank the Kujiale artists and other professionals for their great efforts into editing and labelling millions of models and scenes. We also highly appreciate comments and technical support from <em>Kujiale Rendering Group</em>, as well as helpful discussions and comments from Prof. <a href="https://www.doc.ic.ac.uk/~ajd"><strong>Andrew Davison</strong></a> and other members of <em>Robot Vision Group</em> of Imperial College London. This research is supported by the EPSRC grants PAMELA <a href="http://gow.epsrc.ac.uk/NGBOViewGrant.aspx?GrantRef=EP/K008730/1"><strong>EP/K008730/1</strong></a>, Aerial ABM <a href="http://gow.epsrc.ac.uk/NGBOViewGrant.aspx?GrantRef=EP/N018494/1"><strong>EP/N018494/1</strong></a>, and Imperial College London.
		</p>

<br>
		
			</center>
			<br><br><br><br>
		</div>
	
		<div id="foot">
		  <p>Last updated: 20th December 2017</p></div>
	</div>
	
	</div>
	
	


</body></html>